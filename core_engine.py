# core_engine.py
# ë²”ê³µì¸ Pro v24 Enterprise - Core Data Engine Module (v24.23.2)
# Feature: Full Logic Restoration & No Pass

import streamlit as st
import pandas as pd
from streamlit_gsheets import GSheetsConnection
import urllib.parse
import time
import uuid
import re
import traceback
import math
from datetime import datetime

# ==============================================================================
# [SECTION 1: GLOBAL CONFIGURATION]
# ==============================================================================

SHEET_URL = "https://docs.google.com/spreadsheets/d/1bmTnLu-vMvlAGRSsCI4a8lk00U38covWl5Wfn9JZYVU"

SHEET_GIDS = {
    "ì„ëŒ€": "2063575964", "ì„ëŒ€(ì¢…ë£Œ)": "791354475", 
    "ë§¤ë§¤": "1833762712", "ë§¤ë§¤(ì¢…ë£Œ)": "1597438389",
    "ì„ëŒ€ë¸Œë¦¬í•‘": "982780192", "ë§¤ë§¤ë¸Œë¦¬í•‘": "807085458"
}
SHEET_NAMES = list(SHEET_GIDS.keys())

NUMERIC_COLS = ["ë³´ì¦ê¸ˆ", "ì›”ì°¨ì„", "ê¶Œë¦¬ê¸ˆ", "ê´€ë¦¬ë¹„", "ë§¤ë§¤ê°€", "ìˆ˜ìµë¥ ", "ë©´ì ", "ëŒ€ì§€ë©´ì ", "ì—°ë©´ì ", "ì¸µ"]
STRING_COLS = ["êµ¬ë¶„", "ì§€ì—­_êµ¬", "ì§€ì—­_ë™", "ë²ˆì§€", "ê±´ë¬¼ëª…", "ë‚´ìš©", "ë¹„ê³ "]
REQUIRED_COLS = ["ë²ˆì§€"]

# ==============================================================================
# [SECTION 2: DATA SANITIZATION ENGINE]
# ==============================================================================

def normalize_headers(df):
    df.columns = df.columns.str.replace(' ', '').str.strip()
    synonym_map = {
        "ë³´ì¦ê¸ˆ": ["ë³´ì¦ê¸ˆ(ë§Œì›)", "ê¸°ë³´ì¦ê¸ˆ", "ë³´ì¦ê¸ˆ"],
        "ì›”ì°¨ì„": ["ì›”ì°¨ì„(ë§Œì›)", "ì›”ì„¸(ë§Œì›)", "ì›”ì„¸", "ê¸°ì›”ì„¸"],
        "ê¶Œë¦¬ê¸ˆ": ["ê¶Œë¦¬ê¸ˆ(ë§Œì›)", "ê¶Œë¦¬ê¸ˆ"],
        "ê´€ë¦¬ë¹„": ["ê´€ë¦¬ë¹„(ë§Œì›)", "ê´€ë¦¬ë¹„"],
        "ë§¤ë§¤ê°€": ["ë§¤ë§¤ê°€(ë§Œì›)", "ë§¤ë§¤ê¸ˆì•¡", "ë§¤ë§¤ê°€"],
        "ë©´ì ": ["ì „ìš©ë©´ì (í‰)", "ì‹¤í‰ìˆ˜", "ì „ìš©ë©´ì ", "ë©´ì "],
        "ëŒ€ì§€ë©´ì ": ["ëŒ€ì§€ë©´ì (í‰)", "ëŒ€ì§€", "ëŒ€ì§€ë©´ì "],
        "ì—°ë©´ì ": ["ì—°ë©´ì (í‰)", "ì—°ë©´ì "],
        "ìˆ˜ìµë¥ ": ["ìˆ˜ìµë¥ (%)", "ìˆ˜ìµë¥ "],
        "ì¸µ": ["í•´ë‹¹ì¸µ", "ì¸µ", "ì§€ìƒì¸µ"],
        "ë‚´ìš©": ["ë§¤ë¬¼íŠ¹ì§•", "íŠ¹ì§•", "ë¹„ê³ ", "ë‚´ìš©"],
        "ë²ˆì§€": ["ì§€ì—­_ë²ˆì§€", "ë²ˆì§€", "ì§€ë²ˆ"],
        "êµ¬ë¶„": ["ë§¤ë¬¼êµ¬ë¶„", "êµ¬ë¶„"],
        "ê±´ë¬¼ëª…": ["ê±´ë¬¼ëª…", "ë¹Œë”©ëª…"]
    }
    for standard, aliases in synonym_map.items():
        for alias in aliases:
            clean = alias.replace(' ', '')
            if clean in df.columns:
                df.rename(columns={clean: standard}, inplace=True)
                break 
    return df

def sanitize_dataframe(df):
    for col in NUMERIC_COLS:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', '').str.strip(), errors='coerce').fillna(0)
    for col in STRING_COLS:
        if col in df.columns:
            df[col] = df[col].astype(str).str.replace(r'\s+', ' ', regex=True).str.strip()
    return df.fillna("")

def validate_data_integrity(df):
    errors = []
    for col in REQUIRED_COLS:
        if col not in df.columns: errors.append(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {col}")
        elif df[col].astype(str).str.strip().eq("").any():
            errors.append(f"í•„ìˆ˜ê°’ ëˆ„ë½: {col} ì»¬ëŸ¼ì— ë¹ˆ í–‰ì´ ìˆìŠµë‹ˆë‹¤.")
    if errors: return False, "\n".join(errors)
    return True, "Integrity Check Passed"

# ==============================================================================
# [SECTION 3: CORE LOAD ENGINE]
# ==============================================================================

def initialize_search_state():
    if 'editor_key_version' not in st.session_state: st.session_state.editor_key_version = 0
    defaults = {
        'search_keyword': "", 'exact_bunji': "", 'selected_cat': [], 'selected_gu': [], 'selected_dong': [],
        'min_price': 0.0, 'max_price': 10000000.0, 'min_dep': 0.0, 'max_dep': 1000000.0,
        'min_rent': 0.0, 'max_rent': 10000.0, 'min_kwon': 0.0, 'max_kwon': 100000.0,
        'min_area': 0.0, 'max_area': 10000.0, 'min_land': 0.0, 'max_land': 10000.0,
        'min_total': 0.0, 'max_total': 10000.0, 'min_fl': 0.0, 'max_fl': 100.0, 'is_no_kwon': False
    }
    for k, v in defaults.items():
        if k not in st.session_state: st.session_state[k] = v

def safe_reset():
    for key in list(st.session_state.keys()):
        if key not in ['current_sheet', 'editor_key_version']: del st.session_state[key]
    st.session_state.editor_key_version += 1
    st.cache_data.clear(); st.rerun()

@st.cache_data(ttl=600)
def load_sheet_data(sheet_name):
    gid = SHEET_GIDS.get(sheet_name)
    if not gid: return None
    try:
        df = pd.read_csv(f"{SHEET_URL}/export?format=csv&gid={gid}")
        df = normalize_headers(df)
        df = sanitize_dataframe(df)
        df = df.drop(columns=[c for c in ['ì„ íƒ', 'IronID', 'Unnamed: 0'] if c in df.columns], errors='ignore')
        df['IronID'] = [str(uuid.uuid4()) for _ in range(len(df))]
        df.insert(0, 'ì„ íƒ', False)
        return df
    except: return None

# ==============================================================================
# [SECTION 4: MATCHING & UPDATE ENGINE]
# ==============================================================================

def create_match_signature(df, keys):
    temp_df = df.copy()
    temp_df['_match_sig'] = ""
    for k in keys:
        try:
            if k in NUMERIC_COLS:
                val = pd.to_numeric(temp_df[k].astype(str).str.replace(',', ''), errors='coerce').fillna(0)
                temp_df['_match_sig'] += val.round(1).astype(str).str.replace(r'\.0$', '', regex=True) + "|"
            else:
                val = temp_df[k].astype(str).str[:20] if k == 'ë‚´ìš©' else temp_df[k].astype(str)
                temp_df['_match_sig'] += val.str.replace(r'[^ê°€-í£a-zA-Z0-9]', '', regex=True) + "|"
        except: continue
    return temp_df

def update_single_row(updated_row, sheet_name):
    conn = st.connection("gsheets", type=GSheetsConnection)
    try:
        sheet_data = normalize_headers(conn.read(spreadsheet=SHEET_URL, worksheet=sheet_name, ttl=0))
        match_keys = ['ë²ˆì§€', 'ì¸µ', 'ë©´ì '] 
        valid_keys = [k for k in match_keys if k in sheet_data.columns and k in updated_row]
        
        if len(valid_keys) < 2: return False, "ì‹ë³„ í‚¤ ë¶€ì¡± (ë²ˆì§€/ì¸µ/ë©´ì  í•„ìˆ˜)"
        
        local_sig = ""
        for k in valid_keys:
             val = str(updated_row.get(k, '')).replace(',', '').strip()
             if k in NUMERIC_COLS:
                 try: val = str(round(float(val), 1)).replace('.0', '')
                 except: val = "0"
             else:
                 val = re.sub(r'[^ê°€-í£a-zA-Z0-9]', '', val)
             local_sig += val + "|"
             
        server_sigs = []
        for _, row in sheet_data.iterrows():
            sig = ""
            for k in valid_keys:
                val = str(row.get(k, '')).replace(',', '').strip()
                if k in NUMERIC_COLS:
                    try: val = str(round(float(val), 1)).replace('.0', '')
                    except: val = "0"
                else:
                    val = re.sub(r'[^ê°€-í£a-zA-Z0-9]', '', val)
                sig += val + "|"
            server_sigs.append(sig)
            
        try:
            target_idx = server_sigs.index(local_sig)
            for k, v in updated_row.items():
                if k in sheet_data.columns and k not in ['ì„ íƒ', 'IronID']:
                    if k in NUMERIC_COLS:
                        try: v = float(str(v).replace(',', ''))
                        except: v = 0.0
                    sheet_data.at[target_idx, k] = v
            conn.update(spreadsheet=SHEET_URL, worksheet=sheet_name, data=sheet_data)
            return True, "âœ… ìˆ˜ì • ì‚¬í•­ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."
        except ValueError: return False, "âŒ ì›ë³¸ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e: return False, f"ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}"

def save_updates_to_sheet(edited_df, original_df, sheet_name):
    conn = st.connection("gsheets", type=GSheetsConnection)
    try:
        df_org = original_df.set_index('IronID')
        df_new = edited_df.set_index('IronID')
        changed_ids = [iid for iid in df_org.index.intersection(df_new.index) 
                       if not df_org.loc[iid].drop(['ì„ íƒ'], errors='ignore').astype(str).equals(df_new.loc[iid].drop(['ì„ íƒ'], errors='ignore').astype(str))]
        
        if not changed_ids: return True, "ë³€ê²½ ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.", None

        for attempt in range(3):
            try:
                sheet_data = normalize_headers(conn.read(spreadsheet=SHEET_URL, worksheet=sheet_name, ttl=0))
                valid_keys = [k for k in ['ë²ˆì§€', 'ì¸µ', 'ë©´ì ', 'ë§¤ë§¤ê°€', 'ë³´ì¦ê¸ˆ'] if k in sheet_data.columns and k in df_org.columns]
                if len(valid_keys) < 2: return False, "ì‹ë³„ í‚¤ ë¶€ì¡±", None

                target_sigs = create_match_signature(df_org.loc[changed_ids].reset_index(), valid_keys)['_match_sig'].tolist()
                server_sigs = create_match_signature(sheet_data, valid_keys)
                
                update_count = 0
                for idx, sig in zip(target_sigs, changed_ids):
                    match_idx = server_sigs.index[server_sigs['_match_sig'] == idx].tolist()
                    if match_idx:
                        for col in sheet_data.columns:
                            if col in df_new.columns: sheet_data.at[match_idx[0], col] = df_new.loc[sig, col]
                        update_count += 1
                
                if update_count == 0: return False, "ì›ë³¸ ë°ì´í„° ë§¤ì¹­ ì‹¤íŒ¨", None
                is_v, msg = validate_data_integrity(sheet_data)
                if not is_v: return False, f"ë¬´ê²°ì„± ì˜¤ë¥˜: {msg}", None
                
                conn.update(spreadsheet=SHEET_URL, worksheet=sheet_name, data=sheet_data)
                return True, f"âœ… {update_count}ê±´ ì €ì¥ ì™„ë£Œ!", None
            except Exception as e:
                time.sleep(attempt + 1); last_err = e; continue
        return False, f"ğŸš¨ ì¬ì‹œë„ ì‹¤íŒ¨: {last_err}", None
    except Exception as e: return False, f"ğŸš¨ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}", traceback.format_exc()

def execute_transaction(action_type, target_rows, source_sheet, target_sheet=None):
    conn = st.connection("gsheets", type=GSheetsConnection)
    try:
        if target_rows.empty: return False, "ëŒ€ìƒ ì—†ìŒ", None
        src_df = normalize_headers(conn.read(spreadsheet=SHEET_URL, worksheet=source_sheet, ttl=0))
        target_clean = target_rows.drop(columns=['ì„ íƒ', 'IronID'], errors='ignore')
        v_keys = [k for k in ['ë²ˆì§€', 'ì¸µ', 'ë©´ì ', 'ë³´ì¦ê¸ˆ', 'ë§¤ë§¤ê°€', 'ì›”ì°¨ì„', 'ë‚´ìš©'] if k in src_df.columns and k in target_clean.columns]
        
        src_sig = create_match_signature(src_df, v_keys)
        tgt_sig = create_match_signature(target_clean, v_keys)
        sigs = tgt_sig['_match_sig'].tolist()

        if action_type in ["delete", "move", "restore"]:
            new_src = src_df[~src_sig['_match_sig'].isin(sigs)]
            if len(src_df) == len(new_src): return False, "ë§¤ì¹­ ì‹¤íŒ¨", None
            
            if action_type in ["move", "restore"] and target_sheet:
                tgt_df = normalize_headers(conn.read(spreadsheet=SHEET_URL, worksheet=target_sheet, ttl=0))
                new_tgt = pd.concat([tgt_df, target_clean], ignore_index=True)
                is_v, msg = validate_data_integrity(new_tgt)
                if not is_v: return False, msg, None
                conn.update(spreadsheet=SHEET_URL, worksheet=target_sheet, data=new_tgt)
            
            conn.update(spreadsheet=SHEET_URL, worksheet=source_sheet, data=new_src)
            return True, f"âœ… ì²˜ë¦¬ ì™„ë£Œ", None
        
        elif action_type == "copy":
            tgt_df = normalize_headers(conn.read(spreadsheet=SHEET_URL, worksheet=target_sheet, ttl=0))
            conn.update(spreadsheet=SHEET_URL, worksheet=target_sheet, data=pd.concat([tgt_df, target_clean], ignore_index=True))
            return True, "âœ… ë³µì‚¬ ì™„ë£Œ", None
            
    except Exception as e: return False, str(e), traceback.format_exc()
